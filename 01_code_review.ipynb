{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YiJing Modul Code Review Notebook\n",
    "\n",
    "Dieses Notebook dient zur systematischen Code-Review und zum Testen des YiJing-Moduls.\n",
    "\n",
    "## Bereiche der Review:\n",
    "1. Grundlegende Funktionalität\n",
    "2. Fehlerbehandlung\n",
    "3. Async Support\n",
    "4. Performance\n",
    "5. Ressourcenverwaltung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports und Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "# Logging Setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Projektpfad zum Python-Path hinzufügen\n",
    "project_dir = Path.cwd()  # Da das Notebook im Root liegt\n",
    "if str(project_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(project_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grundlegende Funktionalität\n",
    "\n",
    "Zuerst testen wir die Kernfunktionalität des Moduls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 16:56:26,192 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-12-31 16:56:26,194 - httpx - DEBUG - load_verify_locations cafile='/Users/johanneskaindl/miniconda3/envs/gemini_310/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama3.2:latest\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Auswahl des Modells\n",
    "model_speed = {\n",
    "    'dumb': 'llama3.1:latest',\n",
    "    'vision': 'llama3.2-vision:latest',\n",
    "    'fast': 'llama3.2:1b:latest',\n",
    "    'clever': 'llama3.2:latest',\n",
    "    'assistent': 'dolphin-mistral:latest'\n",
    "    }\n",
    "\n",
    "#selected_model = model_speed['dumb']\n",
    "#selected_model = model_speed['vision']\n",
    "#selected_model = model_speed['fast']\n",
    "selected_model = model_speed['clever']\n",
    "#selected_model = model_speed['uncensored']\n",
    "\n",
    "print(\"Model:\", selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (lines.py, line 22)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/gemini_310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[3], line 2\u001b[0m\n    from yijing import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Documents/0_inbox/2_projekte/1_coding/YijingOracle/yijing/__init__.py:21\u001b[0m\n    from .models import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Documents/0_inbox/2_projekte/1_coding/YijingOracle/yijing/models/__init__.py:9\u001b[0m\n    from .contexts import HypergramData, HexagramContext\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Documents/0_inbox/2_projekte/1_coding/YijingOracle/yijing/models/contexts.py:13\u001b[0m\n    from .hexagrams import Hexagram, Hypergram\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/0_inbox/2_projekte/1_coding/YijingOracle/yijing/models/hexagrams.py:12\u001b[0;36m\n\u001b[0;31m    from .lines import HexagramLine, HypergramLine\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/0_inbox/2_projekte/1_coding/YijingOracle/yijing/models/lines.py:22\u001b[0;36m\u001b[0m\n\u001b[0;31m    class Hype    \"\"\"A single line in a hypergram that can change state.\"\"\"\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Import der Hauptkomponenten\n",
    "from yijing import (\n",
    "    YijingOracle,\n",
    "    cast_hypergram,\n",
    "    generiere_erweiterte_weissagung,\n",
    "    formatiere_weissagung_markdown\n",
    ")\n",
    "from yijing.config import ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test der verschiedenen Modelle\n",
    "models = {\n",
    "    'genai': {\n",
    "        'type': ModelType.GENAI,\n",
    "        'model': 'models/gemini-1.5-flash'\n",
    "    },\n",
    "    'ollama': {\n",
    "        'type': ModelType.OLLAMA,\n",
    "        'model': selected_model\n",
    "    }\n",
    "}\n",
    "\n",
    "# Wähle ein Modell für den Test\n",
    "selected_model = models['ollama']  # oder 'genai'\n",
    "\n",
    "custom_settings = {\n",
    "    \"model_type\": selected_model['type'],\n",
    "    \"active_model\": selected_model['model'],\n",
    "    \"debug\": True\n",
    "}\n",
    "\n",
    "oracle = YijingOracle(custom_settings=custom_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test einer Weissagung\n",
    "test_frage = \"Was sagt das I Ging über meine aktuelle Situation?\"\n",
    "weissagung = oracle.get_response(test_frage)\n",
    "\n",
    "# Ausgabe der Antwort\n",
    "print(\"Strukturierte Antwort:\")\n",
    "pprint(weissagung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_json_viewer import display_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_json(weissagung,\n",
    "             dark_mode=True,\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fehlerbehandlung\n",
    "\n",
    "Testen der Fehlerbehandlung in verschiedenen Szenarien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "from yijing.enums import ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_cases():\n",
    "    \"\"\"Test verschiedener Fehlerfälle für das YijingOracle\"\"\"\n",
    "    \n",
    "    # Test 1: Ungültige Konfiguration\n",
    "    try:\n",
    "        invalid_settings = {\n",
    "            \"model_type\": \"invalid_type\",\n",
    "            \"active_model\": \"\"\n",
    "        }\n",
    "        oracle_invalid = YijingOracle(custom_settings=invalid_settings)\n",
    "        assert False, \"Sollte ValidationError auslösen\"\n",
    "    except ValidationError as e:\n",
    "        print(f\"✓ Erwarteter ValidationError bei ungültiger Konfiguration: {e}\\n\")\n",
    "    \n",
    "    # Test 2: Leere Frage\n",
    "    oracle = YijingOracle(custom_settings={\n",
    "        \"model_type\": ModelType.OLLAMA,\n",
    "        \"active_model\": \"llama3.2:latest\"\n",
    "    })\n",
    "    try:\n",
    "        weissagung = oracle.get_response(\"\")\n",
    "        assert False, \"Sollte ValueError auslösen\"\n",
    "    except ValueError as e:\n",
    "        print(f\"✓ Erwarteter ValueError bei leerer Frage: {e}\\n\")\n",
    "\n",
    "test_error_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Async Support\n",
    "\n",
    "Test der asynchronen Funktionalität."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def test_async_functionality():\n",
    "    \"\"\"Test der asynchronen Funktionen\"\"\"\n",
    "    # Mehrere gleichzeitige Anfragen\n",
    "    fragen = [\n",
    "        \"Was sagt das I Ging über meine Beziehungen?\",\n",
    "        \"Wie entwickelt sich meine berufliche Situation?\",\n",
    "        \"Was sollte ich in der aktuellen Situation beachten?\"\n",
    "    ]\n",
    "    \n",
    "    tasks = [oracle.get_response_async(frage) for frage in fragen]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Ausführung des async Tests\n",
    "async_results = await test_async_functionality()\n",
    "print(\"Async Ergebnisse:\")\n",
    "for i, result in enumerate(async_results, 1):\n",
    "    print(f\"\\nAntwort {i}:\")\n",
    "    print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance\n",
    "\n",
    "Analyse der Performance-Metriken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "\n",
    "def measure_performance(n_iterations=5):\n",
    "    \"\"\"Misst die Performance der Hauptfunktionen\"\"\"\n",
    "    timings = {\n",
    "        'hypergram_gen': [],\n",
    "        'oracle_response': []\n",
    "    }\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        # Zeitmessung für Hypergram-Generierung\n",
    "        start = time.time()\n",
    "        hypergram = cast_hypergram()\n",
    "        timings['hypergram_gen'].append(time.time() - start)\n",
    "        \n",
    "        # Zeitmessung für Oracle-Antwort\n",
    "        start = time.time()\n",
    "        response = oracle.get_response(\"Test Frage\")\n",
    "        timings['oracle_response'].append(time.time() - start)\n",
    "    \n",
    "    # Statistiken berechnen\n",
    "    stats = {}\n",
    "    for key, values in timings.items():\n",
    "        stats[key] = {\n",
    "            'mean': statistics.mean(values),\n",
    "            'std': statistics.stdev(values),\n",
    "            'min': min(values),\n",
    "            'max': max(values)\n",
    "        }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "performance_stats = measure_performance()\n",
    "print(\"Performance Statistiken:\")\n",
    "pprint(performance_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ressourcenverwaltung\n",
    "\n",
    "Überprüfung der Ressourcenverwaltung und des Speicherverbrauchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def monitor_resources(func):\n",
    "    \"\"\"Überwacht Ressourcenverbrauch einer Funktion\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Speicherverbrauch vor Ausführung\n",
    "    mem_before = process.memory_info().rss\n",
    "    \n",
    "    # Funktion ausführen\n",
    "    result = func()\n",
    "    \n",
    "    # Speicherverbrauch nach Ausführung\n",
    "    mem_after = process.memory_info().rss\n",
    "    mem_diff = mem_after - mem_before\n",
    "    \n",
    "    print(f\"Speicherverbrauch: {mem_diff / 1024 / 1024:.2f} MB\")\n",
    "    return result\n",
    "\n",
    "# Test der Ressourcennutzung\n",
    "def test_function():\n",
    "    return oracle.get_response(\"Test Frage\")\n",
    "\n",
    "result = monitor_resources(test_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "Basierend auf den Tests können wir folgende Aspekte analysieren:\n",
    "1. Funktionalität und Korrektheit\n",
    "2. Fehlerbehandlung und Robustheit\n",
    "3. Performance und Skalierbarkeit\n",
    "4. Ressourceneffizienz\n",
    "5. Code-Qualität und Wartbarkeit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
