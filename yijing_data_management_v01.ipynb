{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texterfassung Steuerzentrale für Yijing"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports und Konfiguration"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API-Konfiguration"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguration des API-Schlüssels\n",
    "api_key = os.environ.get(\"API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Die Umgebungsvariable 'API_KEY' ist nicht gesetzt.\")\n",
    "genai.configure(api_key=api_key)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellwahl"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl des Modells\n",
    "model_speed = {\n",
    "    'dumb': 'gemini-1.5-flash-8b',\n",
    "    'fast': 'gemini-1.5-flash-latest',\n",
    "    'clever': 'gemini-1.5-pro-latest',\n",
    "    'experimental': 'gemini-exp-1121',\n",
    "}\n",
    "model_type = os.getenv(\"MODEL_TYPE\", model_speed['experimental'])\n",
    "print(\"Verwendetes Modell:\", model_type)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenimport"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yijing Text einlesen"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yijing_txt_path = Path('yijing/resources/yijing.txt')\n",
    "\n",
    "# Funktion zum Lesen des Yijing-Texts\n",
    "def read_yijing_txt(path: Path = yijing_txt_path) -> str:\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Laden der Daten\n",
    "yijing_txt = read_yijing_txt()\n",
    "print(\"Yijing-Text erfolgreich geladen.\")"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erste Einblicke in die Daten"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige der ersten 500 Zeichen des Yijing-Texts\n",
    "print(yijing_txt[:500])"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datenverarbeitung"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strukturierter JSON-Text des ersten Kapitels"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yijing_processed = \"\"\"\n",
    "{\n",
    "  \"hexagram\": {\n",
    "    \"name\": \"GUAI / DER DURCHBRUCH\",\n",
    "    \"subtitle\": \"Die Entschlossenheit\",\n",
    "    \"trigrams\": {\n",
    "      \"above\": {\n",
    "        \"name\": \"Dui\",\n",
    "        \"attributes\": \"das Heitere, der See\"\n",
    "      },\n",
    "      \"below\": {\n",
    "        \"name\": \"Kien\",\n",
    "        \"attributes\": \"das Schöpferische, der Himmel\"\n",
    "      }\n",
    "    },\n",
    "    \"meaning\": {\n",
    "      \"description\": \"Das Zeichen bedeutet einerseits einen Durchbruch nach lange angesammelter Spannung...\",\n",
    "      \"season\": \"dritter Monat (April-Mai)\"\n",
    "    }\n",
    "  },\n",
    "  \"judgment\": {\n",
    "    \"description\": \"Der Durchbruch. Entschlossen muß man am Hof des Königs die Sache bekanntmachen...\",\n",
    "    \"analysis\": [\n",
    "      \"Leidenschaft und Vernunft können nicht zusammen bestehen...\",\n",
    "      \"Entschlossenheit muß auf Stärke und Freundlichkeit beruhen...\"\n",
    "    ]\n",
    "  },\n",
    "  \"image\": {\n",
    "    \"description\": \"Der See ist an den Himmel emporgestiegen...\",\n",
    "    \"lesson\": \"Der Edle spendet Reichtum nach unten hin...\",\n",
    "    \"warning\": \"Sammeln führt zu Zerstreuen...\"\n",
    "  },\n",
    "  \"lines\": [\n",
    "    {\n",
    "      \"position\": \"Anfangs eine\",\n",
    "      \"text\": \"Mächtig in den vorwärtsschreitenden Zehen...\",\n",
    "      \"interpretation\": \"Zu Beginn ist entschlossenes Voranschreiten schwierig...\"\n",
    "    }\n",
    "    // Weitere Linien können hier hinzugefügt werden\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Umwandlung des JSON-Textes in ein Python-Dictionary\n",
    "yijing_data = json.loads(yijing_processed)\n",
    "print(\"Erstes Kapitel erfolgreich verarbeitet.\")"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funktionen zur Verarbeitung eines Hexagramms"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hexagram(text: str, model: genai.GenerativeModel) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Verarbeitet einen Hexagramm-Text und gibt strukturierte Daten zurück.\n",
    "    \"\"\"\n",
    "    prompt = HEXAGRAM_PROMPT + text\n",
    "    result = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=None  # Verwenden Sie None, wenn kein Schema benötigt wird\n",
    "        ),\n",
    "    )\n",
    "    return result.candidates[0].content"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialisierung des Modells"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systemanweisung für das Modell"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEXAGRAM_PROMPT = \"\"\"\n",
    "Du bist ein I Ging-Experte mit der Aufgabe, Hexagramm-Texte zu analysieren und in ein spezifisches JSON-Format zu überführen.\n",
    "\n",
    "Wandle den Eingabetext in folgendes Format um:\n",
    "\n",
    "{\n",
    "  \"hexagram\": {\n",
    "    \"name\": \"Name des Hexagramms\",\n",
    "    \"subtitle\": \"Untertitel\",\n",
    "    \"trigrams\": {\n",
    "      \"above\": {\"name\": \"\", \"attributes\": \"\"},\n",
    "      \"below\": {\"name\": \"\", \"attributes\": \"\"}\n",
    "    },\n",
    "    \"meaning\": {\"description\": \"\", \"season\": \"\"}\n",
    "  },\n",
    "  \"judgment\": {\"description\": \"\", \"analysis\": [\"\"]},\n",
    "  \"image\": {\"description\": \"\", \"lesson\": \"\", \"warning\": \"\"},\n",
    "  \"lines\": [\n",
    "    {\"position\": \"\", \"text\": \"\", \"interpretation\": \"\"}\n",
    "    // Weitere Linien\n",
    "  ]\n",
    "}\n",
    "\n",
    "Analysiere nun den folgenden Hexagramm-Text und gib ihn im spezifizierten JSON-Format zurück:\n",
    "\"\"\""
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = HEXAGRAM_PROMPT"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Modells\n",
    "model = genai.GenerativeModel(\n",
    "    model_type,\n",
    "    system_instruction=instruction\n",
    ")\n",
    "\n",
    "# Chat-Instanz starten\n",
    "chat = model.start_chat()\n",
    "print(\"Modell und Chat-Instanz erfolgreich initialisiert.\")"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verarbeitung und Export"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hexagramm verarbeiten und anzeigen"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hexagram_text(hexagram_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Verarbeitet einen Hexagramm-Text und gibt strukturierte Daten zurück.\n",
    "\n",
    "    Args:\n",
    "        hexagram_text (str): Der Hexagramm-Text.\n",
    "\n",
    "    Returns:\n",
    "        dict: Strukturierte Daten des Hexagramms.\n",
    "    \"\"\"\n",
    "    result = chat.send_message(hexagram_text)\n",
    "\n",
    "    # Überprüfen, ob die Antwort Teile enthält\n",
    "    if hasattr(result, 'parts') and len(result.parts) > 0:\n",
    "        json_text = result.parts[0].text\n",
    "        # Entfernen von Codeblöcken, falls vorhanden\n",
    "        formatted_text = json_text.strip('```json\\n').strip('```')\n",
    "        \n",
    "        try:\n",
    "            # Laden des JSON in ein Python-Dictionary\n",
    "            data = json.loads(formatted_text)\n",
    "            display(Markdown(\"### Verarbeitetes Hexagramm\"))\n",
    "            display(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Fehler beim Parsen des JSON.\")\n",
    "    else:\n",
    "        print(\"Keine Antwortteile gefunden.\")\n",
    "    \n",
    "    return {}"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielhafte Nutzung mit dem ersten Kapitel\n",
    "first_chapter_text = yijing_chapters[0] if 'yijing_chapters' in locals() else yijing_txt[:1000]\n",
    "extracted_hexagram = process_hexagram_text(first_chapter_text)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speicherung der Daten als JSON"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hexagram_json(hexagram_data: Dict[str, Any], output_dir: Path, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Speichert die Hexagramm-Daten als JSON-Datei.\n",
    "\n",
    "    Args:\n",
    "        hexagram_data (dict): Strukturierte Hexagramm-Daten.\n",
    "        output_dir (Path): Verzeichnis zum Speichern der JSON-Dateien.\n",
    "        filename (str): Name der JSON-Datei.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_file = output_dir / filename\n",
    "    with output_file.open('w', encoding='utf-8') as f:\n",
    "        json.dump(hexagram_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Daten gespeichert unter {output_file}\")"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des extrahierten Hexagramms\n",
    "if extracted_hexagram:\n",
    "    save_hexagram_json(extracted_hexagram, Path('export/hexagram_json'), 'hexagram_01.json')"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export der Linien in ein DataFrame"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_lines_to_dataframe(hexagram_data: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Exportiert die Linien eines Hexagramms in ein pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        hexagram_data (dict): Strukturierte Hexagramm-Daten.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit den Linieninformationen.\n",
    "    \"\"\"\n",
    "    lines = hexagram_data.get('lines', [])\n",
    "    lines_df = pd.DataFrame(lines)\n",
    "    return lines_df\n",
    "\n",
    "# Erstellen des DataFrames\n",
    "lines_df = export_lines_to_dataframe(extracted_hexagram)\n",
    "display(lines_df)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Zusätzliche Analysen (Optional)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel: Analyse der Interpretationen"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not lines_df.empty:\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    \n",
    "    # Zusammenführen aller Interpretationen\n",
    "    all_interpretations = ' '.join(lines_df['interpretation'].dropna().tolist())\n",
    "    \n",
    "    # Extrahieren von Wörtern\n",
    "    words = re.findall(r'\\w+', all_interpretations.lower())\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Anzeige der häufigsten Wörter\n",
    "    common_words = word_counts.most_common(10)\n",
    "    common_df = pd.DataFrame(common_words, columns=['Wort', 'Häufigkeit'])\n",
    "    display(Markdown(\"### Häufigste Wörter in den Interpretationen\"))\n",
    "    display(common_df)"
  ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ende des Notebooks"
  ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
